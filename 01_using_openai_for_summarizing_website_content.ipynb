{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPggynV+g7KWA0ApCYIyUt4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shriansh16/LLM_Engineering/blob/main/01_using_openai_for_summarizing_website_content.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uJKkriOlzgBn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from openai import OpenAI\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXGG_NQT0WTH",
        "outputId": "9e94085b-b268-46fd-c9ff-83c93efbb08d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.51.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.51.0-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.5/383.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.5.0 openai-1.51.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY','')"
      ],
      "metadata": {
        "id": "7vBKyyNz0YJf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai=OpenAI()"
      ],
      "metadata": {
        "id": "__duyzCA1il2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A class to represent a Webpage\n",
        "\n",
        "class Website:\n",
        "    url: str\n",
        "    title: str\n",
        "    text: str\n",
        "\n",
        "    def __init__(self, url):\n",
        "        self.url = url\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        self.title = soup.title.string if soup.title else \"No title found\"\n",
        "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
        "            irrelevant.decompose()\n",
        "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
      ],
      "metadata": {
        "id": "cZAvF4Om1m8G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try one out\n",
        "\n",
        "ed = Website(\"https://edwarddonner.com\")\n",
        "print(ed.title)\n",
        "print(ed.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFd38V1q2KqM",
        "outputId": "658d6db9-ae38-4450-bf72-e1c8ca844e1d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Home - Edward Donner\n",
            "Home\n",
            "Outsmart\n",
            "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
            "About\n",
            "Posts\n",
            "Well, hi there.\n",
            "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
            "very\n",
            "amateur) and losing myself in\n",
            "Hacker News\n",
            ", nodding my head sagely to things I only half understand.\n",
            "I’m the co-founder and CTO of\n",
            "Nebula.io\n",
            ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
            "acquired in 2021\n",
            ".\n",
            "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
            "patented\n",
            "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
            "Connect\n",
            "with me for more!\n",
            "August 6, 2024\n",
            "Outsmart LLM Arena – a battle of diplomacy and deviousness\n",
            "June 26, 2024\n",
            "Choosing the Right LLM: Toolkit and Resources\n",
            "February 7, 2024\n",
            "Fine-tuning an LLM on your texts: a simulation of you\n",
            "January 31, 2024\n",
            "Fine-tuning an LLM on your texts: part 4 – QLoRA\n",
            "Navigation\n",
            "Home\n",
            "Outsmart\n",
            "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
            "About\n",
            "Posts\n",
            "Get in touch\n",
            "ed [at] edwarddonner [dot] com\n",
            "www.edwarddonner.com\n",
            "Follow me\n",
            "LinkedIn\n",
            "Twitter\n",
            "Facebook\n",
            "Subscribe to newsletter\n",
            "Type your email…\n",
            "Subscribe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Types of prompts\n",
        "You may know this already - but if not, you will get very familiar with it!\n",
        "\n",
        "Models like GPT4o have been trained to receive instructions in a particular way.\n",
        "\n",
        "They expect to receive:\n",
        "\n",
        "A system prompt that tells them what task they are performing and what tone they should use\n",
        "\n",
        "A user prompt -- the conversation starter that they should reply to"
      ],
      "metadata": {
        "id": "8WjPaYO15lKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
        "and provides a short summary, ignoring text that might be navigation related. \\\n",
        "Respond in markdown.\""
      ],
      "metadata": {
        "id": "3EwlFlsn5mGT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_prompt_for(website):\n",
        "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
        "    user_prompt += \"The contents of this website is as follows; \\\n",
        "please provide a short summary of this website in markdown. \\\n",
        "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
        "    user_prompt += website.text\n",
        "    return user_prompt"
      ],
      "metadata": {
        "id": "411UyxNF5q6E"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Messages\n",
        "The API from OpenAI expects to receive messages in a particular structure. Many of the other APIs share this structure:\n",
        "\n",
        "[\n",
        "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
        "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
        "]"
      ],
      "metadata": {
        "id": "XcWn1dlK50GZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def messages_for(website):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
        "    ]"
      ],
      "metadata": {
        "id": "lQY2l-2U5vwl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(url):\n",
        "    website = Website(url)\n",
        "    response = openai.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = messages_for(website)\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "N33iCqop53LF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(\"https://edwarddonner.com\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "BMdK5ZS158pm",
        "outputId": "a046ac25-94be-4e73-910a-e08963a909b2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Website Summary\\n\\nThe website belongs to Edward Donner and mainly focuses on LLMs (Large Language Models) and AI-related topics. Edward Donner is the co-founder and CTO of Nebula.io, an AI company working on talent sourcing and management. He has previously founded an AI startup untapt that was acquired in 2021. The site features posts on topics like fine-tuning LLMs and choosing the right LLM, along with an event called Outsmart LLM Arena, where LLMs battle in diplomacy and deviousness. Edward Donner is also interested in DJing and electronic music production. The website provides ways to connect with Edward Donner via email and social media.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_summary(url):\n",
        "    summary = summarize(url)\n",
        "    display(Markdown(summary))"
      ],
      "metadata": {
        "id": "4IpAQl2i5_GW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_summary(\"https://edwarddonner.com\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "h-u7kz8G6Q-6",
        "outputId": "8e196326-01cd-4ebd-90f2-cf12e8dc4875"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Website Summary\nThe website belongs to Edward Donner, who is the co-founder and CTO of Nebula.io, applying AI to help people pursue their potential. Edward has a background in AI startups and music production. The site includes information about an arena called Outsmart, where LLMs compete in diplomacy and deviousness, as well as posts related to LLMs. It also lists upcoming and past events related to LLMs and offers ways to connect with Edward."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tg-0nKag6S1o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}