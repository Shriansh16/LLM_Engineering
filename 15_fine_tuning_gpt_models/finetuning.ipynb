{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\HealthCare_AI_Assistant_system\\wound_analysis\\henv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\HealthCare_AI_Assistant_system\\wound_analysis\\henv\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Shrian Singh\\.cache\\huggingface\\hub\\models--meta-llama--Meta-Llama-3.1-8B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from items import Item\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', '')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (manager).\n",
      "Your token has been saved to C:\\Users\\Shrian Singh\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Log in to HuggingFace\n",
    "\n",
    "hf_token = os.environ['HF_TOKEN']\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's avoid curating all our data again! Load in the pickle files:\n",
    "\n",
    "with open('train.pkl', 'rb') as file:\n",
    "    train = pickle.load(file)\n",
    "\n",
    "with open('test.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI recommends fine-tuning with populations of 50-100 examples\n",
    "# But as our examples are very small, I'm suggesting we go with 500 examples (and 1 epoch)\n",
    "\n",
    "fine_tune_train = train[:100]\n",
    "fine_tune_validation = train[100:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "##### Prepare our data for fine-tuning in JSONL (JSON Lines) format and upload to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's work on a good prompt for a Frontier model\n",
    "# Notice that I'm removing the \" to the nearest dollar\"\n",
    "# When we train our own models, we'll need to make the problem as easy as possible, \n",
    "# but a Frontier model needs no such simplification.\n",
    "\n",
    "def messages_for(item):\n",
    "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt = item.test_prompt().replace(\" to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": f\"Price is ${item.price:.2f}\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the items into a list of json objects - a \"jsonl\" string\n",
    "# Each row represents a message in the form:\n",
    "# {\"messages\" : [{\"role\": \"system\", \"content\": \"You estimate prices...\n",
    "\n",
    "\n",
    "def make_jsonl(items):\n",
    "    result = \"\"\n",
    "    for item in items:\n",
    "        messages = messages_for(item)\n",
    "        messages_str = json.dumps(messages)\n",
    "        result += '{\"messages\": ' + messages_str +'}\\n'\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the items into jsonl and write them to a file\n",
    "\n",
    "def write_jsonl(items, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        jsonl = make_jsonl(items)\n",
    "        f.write(jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(fine_tune_train, \"fine_tune_train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(fine_tune_validation, \"fine_tune_validation.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fine_tune_train.jsonl\", \"rb\") as f:\n",
    "    train_file = openai.files.create(file=f, purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-RWTco4ZLDhxNtmxdWYaiWJ3g', bytes=97039, created_at=1729248766, filename='fine_tune_train.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fine_tune_validation.jsonl\", \"rb\") as f:\n",
    "    validation_file = openai.files.create(file=f, purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-oXTiQBQn55qANtQbz8VM7RUW', bytes=48052, created_at=1729248786, filename='fine_tune_validation.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "#### NOW ITS TIME FINE TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-MXIj43gI91euQSqSNvmnFqGL', created_at=1729249747, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=1, batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-iumMGS1Wm1CV21idNVA5Y6on', result_files=[], seed=42, status='validating_files', trained_tokens=None, training_file='file-RWTco4ZLDhxNtmxdWYaiWJ3g', validation_file='file-oXTiQBQn55qANtQbz8VM7RUW', estimated_finish=None, integrations=[], user_provided_suffix='pricer')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.fine_tuning.jobs.create(\n",
    "    training_file=train_file.id,\n",
    "    validation_file=validation_file.id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    seed=42,\n",
    "    hyperparameters={\"n_epochs\": 1},\n",
    "    suffix=\"pricer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-MXIj43gI91euQSqSNvmnFqGL', created_at=1729249747, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=1, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-iumMGS1Wm1CV21idNVA5Y6on', result_files=[], seed=42, status='validating_files', trained_tokens=None, training_file='file-RWTco4ZLDhxNtmxdWYaiWJ3g', validation_file='file-oXTiQBQn55qANtQbz8VM7RUW', estimated_finish=None, integrations=[], user_provided_suffix='pricer')], object='list', has_more=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.fine_tuning.jobs.list(limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = openai.fine_tuning.jobs.list(limit=1).data[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ftjob-MXIj43gI91euQSqSNvmnFqGL'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-MXIj43gI91euQSqSNvmnFqGL', created_at=1729249747, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=1, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-iumMGS1Wm1CV21idNVA5Y6on', result_files=[], seed=42, status='running', trained_tokens=None, training_file='file-RWTco4ZLDhxNtmxdWYaiWJ3g', validation_file='file-oXTiQBQn55qANtQbz8VM7RUW', estimated_finish=None, integrations=[], user_provided_suffix='pricer')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.fine_tuning.jobs.retrieve(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FineTuningJobEvent(id='ftevent-0wcmrNhmn3CjkjlHKSQAUNGq', created_at=1729250090, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message'),\n",
       " FineTuningJobEvent(id='ftevent-Q9h8N5nwD2005weaRH8lGFnU', created_at=1729250087, level='info', message='New fine-tuned model created', object='fine_tuning.job.event', data={}, type='message'),\n",
       " FineTuningJobEvent(id='ftevent-oMcW9Fj7DS9K5RC5PrDmoGcO', created_at=1729250076, level='info', message='Step 100/100: training loss=1.02, validation loss=0.78, full validation loss=0.71', object='fine_tuning.job.event', data={'step': 100, 'train_loss': 1.016002893447876, 'valid_loss': 0.7818808555603027, 'total_steps': 100, 'full_valid_loss': 0.7096808433532715, 'train_mean_token_accuracy': 0.75, 'valid_mean_token_accuracy': 0.75, 'full_valid_mean_token_accuracy': 0.8375}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-Wb1ClPYnB80C1gtA9yjHDbzL', created_at=1729250071, level='info', message='Step 99/100: training loss=0.92, validation loss=0.66', object='fine_tuning.job.event', data={'step': 99, 'train_loss': 0.9249932765960693, 'valid_loss': 0.6595931053161621, 'total_steps': 100, 'train_mean_token_accuracy': 0.75, 'valid_mean_token_accuracy': 0.875}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-OsALeSGT6iGHVdl7QjqeRaml', created_at=1729250069, level='info', message='Step 98/100: training loss=0.88, validation loss=0.41', object='fine_tuning.job.event', data={'step': 98, 'train_loss': 0.8846960067749023, 'valid_loss': 0.40657901763916016, 'total_steps': 100, 'train_mean_token_accuracy': 0.75, 'valid_mean_token_accuracy': 0.875}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-M5S9NzwIVGrAalq6VTHJYrJB', created_at=1729250069, level='info', message='Step 97/100: training loss=0.67, validation loss=0.42', object='fine_tuning.job.event', data={'step': 97, 'train_loss': 0.6665246486663818, 'valid_loss': 0.4198009967803955, 'total_steps': 100, 'train_mean_token_accuracy': 0.875, 'valid_mean_token_accuracy': 0.875}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-QPwzd9uxdXnGnz0LLBZIgPXX', created_at=1729250066, level='info', message='Step 96/100: training loss=1.27, validation loss=0.96', object='fine_tuning.job.event', data={'step': 96, 'train_loss': 1.273235559463501, 'valid_loss': 0.9649567604064941, 'total_steps': 100, 'train_mean_token_accuracy': 0.75, 'valid_mean_token_accuracy': 0.75}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-3dqlhb77oua1EL0h1F9vPS5z', created_at=1729250064, level='info', message='Step 95/100: training loss=0.41, validation loss=1.22', object='fine_tuning.job.event', data={'step': 95, 'train_loss': 0.41278767585754395, 'valid_loss': 1.220827579498291, 'total_steps': 100, 'train_mean_token_accuracy': 0.875, 'valid_mean_token_accuracy': 0.75}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-am6Hn2KquXKL3fv1bXqbkg6W', created_at=1729250064, level='info', message='Step 94/100: training loss=0.21, validation loss=0.96', object='fine_tuning.job.event', data={'step': 94, 'train_loss': 0.2145230770111084, 'valid_loss': 0.9603779315948486, 'total_steps': 100, 'train_mean_token_accuracy': 1.0, 'valid_mean_token_accuracy': 0.75}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-qn7hwJtoDgzrbqHgffBrV2th', created_at=1729250062, level='info', message='Step 93/100: training loss=0.39, validation loss=0.93', object='fine_tuning.job.event', data={'step': 93, 'train_loss': 0.3946685791015625, 'valid_loss': 0.9254000186920166, 'total_steps': 100, 'train_mean_token_accuracy': 0.875, 'valid_mean_token_accuracy': 0.75}, type='metrics')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets use our fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model_name = openai.fine_tuning.jobs.retrieve(job_id).fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prompt\n",
    "\n",
    "def messages_for(item):\n",
    "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt = item.test_prompt().replace(\" to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to extract the price from a string\n",
    "\n",
    "def get_price(s):\n",
    "    s = s.replace('$','').replace(',','')\n",
    "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
    "    return float(match.group()) if match else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gpt_fine_tuned(item):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=fine_tuned_model_name, \n",
    "        messages=messages_for(item),\n",
    "        seed=42,\n",
    "        max_tokens=7\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    return get_price(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test[0].price)\n",
    "print(gpt_fine_tuned(test[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
