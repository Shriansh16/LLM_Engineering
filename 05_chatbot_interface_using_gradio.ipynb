{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOd9S8RUoTHmgQfuLaxz86G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shriansh16/LLM_Engineering/blob/main/05_chatbot_interface_using_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2K_FeKGmVnu1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', '')\n",
        "os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', '')\n",
        "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY', '')"
      ],
      "metadata": {
        "id": "EaHXA-M8WAxJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai = OpenAI()\n",
        "MODEL = 'gpt-3.5-turbo'"
      ],
      "metadata": {
        "id": "BPnugYcvWKws"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant\""
      ],
      "metadata": {
        "id": "FPv3h5qRWO6c"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
        "    for user_message, assistant_message in history:\n",
        "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    print(\"History is:\")\n",
        "    print(history)\n",
        "    print(\"And messages is:\")\n",
        "    print(messages)\n",
        "\n",
        "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
        "\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        yield response"
      ],
      "metadata": {
        "id": "Gd3aOcJaWQ8d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(fn=chat).launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "GqjvkdU9Wh0t",
        "outputId": "247a3f68-b927-4d67-9d88-430eebc12d06"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e453be66a4ade15e66.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e453be66a4ade15e66.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4VwLEzjvWlHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trying multi shot prompts"
      ],
      "metadata": {
        "id": "DBe-z3O_YXn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
        "the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
        "For example, if the customer says 'I'm looking to buy a hat', \\\n",
        "you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales evemt.'\\\n",
        "Encourage the customer to buy hats if they are unsure what to get.\""
      ],
      "metadata": {
        "id": "UVx3BPxEYbC7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
        "    for user_message, assistant_message in history:\n",
        "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
        "\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        yield response"
      ],
      "metadata": {
        "id": "dN1JtKCQYec8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(fn=chat).launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "Kz8MjxCUYhLb",
        "outputId": "8ae39062-698f-4c34-dba0-738cebdff9c3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://248158e61b24bc0b63.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://248158e61b24bc0b63.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_message += \"\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, \\\n",
        "but remind the customer to look at hats!\""
      ],
      "metadata": {
        "id": "zjpZnox8YjeL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
        "    for user_message, assistant_message in history:\n",
        "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
        "\n",
        "    if 'belt' in message:\n",
        "        messages.append({\"role\": \"system\", \"content\": \"For added context, the store does not sell belts, \\\n",
        "but be sure to point out other items on sale\"})\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
        "\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        yield response"
      ],
      "metadata": {
        "id": "kDprwivcZUDB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(fn=chat).launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "k_pOLylxZW2y",
        "outputId": "faf7ca81-9857-47b1-d38c-914de1bbe46a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://349b1e601a63a3298d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://349b1e601a63a3298d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f1-JsqxQZxuj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}