{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shriansh16/LLM_Engineering/blob/main/21_finetuning_llama3_for_AI_Companion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e9eecbf-bd62-4c23-921d-b32811e307a1",
      "metadata": {
        "id": "8e9eecbf-bd62-4c23-921d-b32811e307a1",
        "outputId": "05100f52-863b-4db5-f37c-c2be321fdfd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets==2.21.0 requests torch peft bitsandbytes transformers==4.43.1 trl accelerate sentencepiece\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7b94509-80d1-4998-ae04-df3e3ef880c4",
      "metadata": {
        "id": "f7b94509-80d1-4998-ae04-df3e3ef880c4"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from huggingface_hub import login\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, set_seed\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from datetime import datetime\n",
        "from transformers import BitsAndBytesConfig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "352b2705-c276-49ac-8f6e-4bbad3b99aeb",
      "metadata": {
        "id": "352b2705-c276-49ac-8f6e-4bbad3b99aeb"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "\n",
        "BASE_MODEL = \"meta-llama/Meta-Llama-3-8B\"\n",
        "PROJECT_NAME = \"AI COMPANION\"\n",
        "HF_USER = \"MLsheenu\" # your HF name here!\n",
        "\n",
        "# Data\n",
        "\n",
        "DATASET_NAME = f\"AdithyaSK/Avalon_instruction_30k\"\n",
        "# Or just use the one I've uploaded\n",
        "# DATASET_NAME = \"ed-donner/pricer-data\"\n",
        "MAX_SEQUENCE_LENGTH = 2048\n",
        "\n",
        "# Run name for saving the model in the hub\n",
        "\n",
        "RUN_NAME =  f\"{datetime.now():%Y-%m-%d_%H.%M.%S}\"\n",
        "PROJECT_RUN_NAME = f\"{PROJECT_NAME}-{RUN_NAME}\"\n",
        "HUB_MODEL_NAME = f\"{HF_USER}/{PROJECT_RUN_NAME}\"\n",
        "\n",
        "# Hyperparameters for QLoRA\n",
        "\n",
        "LORA_R = 32\n",
        "LORA_ALPHA = 64\n",
        "TARGET_MODULES = [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
        "LORA_DROPOUT = 0.1\n",
        "QUANT_4_BIT = True\n",
        "\n",
        "# Hyperparameters for Training\n",
        "\n",
        "EPOCHS = 2\n",
        "BATCH_SIZE = 4\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "LEARNING_RATE = 1e-4\n",
        "LR_SCHEDULER_TYPE = 'cosine'\n",
        "WARMUP_RATIO = 0.03\n",
        "OPTIMIZER = \"paged_adamw_32bit\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc841bac-6e6f-42e5-8100-75282ebbd6ed",
      "metadata": {
        "id": "bc841bac-6e6f-42e5-8100-75282ebbd6ed"
      },
      "outputs": [],
      "source": [
        "# Log in to HuggingFace\n",
        "\n",
        "hf_token = \"\"\n",
        "login(hf_token, add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "161ef84a-4830-40d6-aa9a-dc51285e2802",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "7b445f57704843dfadd7b0f024470051",
            "e97307398c6f4c8ea79c8e74b905cf72",
            "b2e209c85f5a4c109afc0a3dbd8b03e2"
          ]
        },
        "id": "161ef84a-4830-40d6-aa9a-dc51285e2802",
        "outputId": "8c57723c-6a62-4ba3-ab56-3fd89200b887"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b445f57704843dfadd7b0f024470051",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/453 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e97307398c6f4c8ea79c8e74b905cf72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/9.05M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2e209c85f5a4c109afc0a3dbd8b03e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/29655 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = load_dataset(DATASET_NAME)\n",
        "train = dataset['train']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "994e8573-02d9-44d0-976f-2de60c47864b",
      "metadata": {
        "id": "994e8573-02d9-44d0-976f-2de60c47864b"
      },
      "outputs": [],
      "source": [
        "# pick the right quantization\n",
        "\n",
        "if QUANT_4_BIT:\n",
        "  quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        "  )\n",
        "else:\n",
        "  quant_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        "    bnb_8bit_compute_dtype=torch.bfloat16\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07557f28-35af-46d3-90f2-01b214d3f7b9",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "0fcbc17e0f8b433f85c9ea090b9eb7a2",
            "8a5fa2e2547844fd889cce773ef38de8",
            "31b0ad87d73f45aeac56b8420679f15f",
            "92b3ff3be9584fdbafa691fbac88c649",
            "b8fe466cb02f4cc0b60c29b26f92f979",
            "d660ab218e334a57be6fcb71ce6dbffe",
            "5e96843e7d6f46c6b416e989f73ef4c1",
            "6b1c4094e31a4ffa97a8879b70b6785b",
            "3413843251744c82a8c3330db292e6a1",
            "a92d694864144acebca617a73c7c45e0",
            "7d4d563c4464474f8bb1d10e2b259e90",
            "008800ced25b406ca0c7ee73e41ff1f8"
          ]
        },
        "id": "07557f28-35af-46d3-90f2-01b214d3f7b9",
        "outputId": "dde11129-7fd2-4a72-bf96-5b677792285c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fcbc17e0f8b433f85c9ea090b9eb7a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a5fa2e2547844fd889cce773ef38de8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31b0ad87d73f45aeac56b8420679f15f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92b3ff3be9584fdbafa691fbac88c649",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8fe466cb02f4cc0b60c29b26f92f979",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d660ab218e334a57be6fcb71ce6dbffe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e96843e7d6f46c6b416e989f73ef4c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b1c4094e31a4ffa97a8879b70b6785b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3413843251744c82a8c3330db292e6a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a92d694864144acebca617a73c7c45e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d4d563c4464474f8bb1d10e2b259e90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "008800ced25b406ca0c7ee73e41ff1f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Load the Tokenizer and the Model\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    quantization_config=quant_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "base_model.generation_config.pad_token_id = tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa3ee339-1165-4289-91e3-85313a1b16a3",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "5173b1972a554c7cb37fd93d1cf0ab0c"
          ]
        },
        "id": "aa3ee339-1165-4289-91e3-85313a1b16a3",
        "outputId": "51d898e9-429c-410b-cc2e-caec12efa728"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5173b1972a554c7cb37fd93d1cf0ab0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/29655 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# First, specify the configuration parameters for LoRA\n",
        "\n",
        "lora_parameters = LoraConfig(\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    r=LORA_R,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=TARGET_MODULES,\n",
        ")\n",
        "# Next, specify the general configuration parameters for training\n",
        "\n",
        "train_parameters = SFTConfig(\n",
        "    output_dir=PROJECT_RUN_NAME,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=1,\n",
        "    eval_strategy=\"no\",\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "    optim=OPTIMIZER,\n",
        "    save_total_limit=10,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=WARMUP_RATIO,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
        "    run_name=RUN_NAME,\n",
        "    max_seq_length=MAX_SEQUENCE_LENGTH,\n",
        "    dataset_text_field=\"text\"\n",
        ")\n",
        "# And now, the Supervised Fine Tuning Trainer will carry out the fine-tuning\n",
        "# Given these 2 sets of configuration parameters\n",
        "\n",
        "fine_tuning = SFTTrainer(\n",
        "    model=base_model,\n",
        "    train_dataset=train,\n",
        "    peft_config=lora_parameters,\n",
        "    tokenizer=tokenizer,\n",
        "    args=train_parameters\n",
        ")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6324230-fa86-4672-ad05-d40da3724793",
      "metadata": {
        "id": "b6324230-fa86-4672-ad05-d40da3724793",
        "outputId": "03bb65b3-0d43-4c79-ea2a-deeae668278c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14828' max='14828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14828/14828 2:37:20, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.609900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.408600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.377400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.355500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.338300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.331200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.332800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.336400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.318500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.313200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>1.304100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.311800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>1.305900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>1.287300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>1.282600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>1.189800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>1.182300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>1.172800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>1.183000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>1.175400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>1.176200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>1.183700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>1.179400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>1.175200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>1.174300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>1.162600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>1.166600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>1.176800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>1.170500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=14828, training_loss=1.262781921666621, metrics={'train_runtime': 9442.8189, 'train_samples_per_second': 6.281, 'train_steps_per_second': 1.57, 'total_flos': 3.33795207594369e+17, 'train_loss': 1.262781921666621, 'epoch': 2.0})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fine-tune!\n",
        "fine_tuning.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe099778-71f8-46f1-bff7-dae1b30fcc88",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "5e81b0627ad24768a8010cfeb25b8ec9"
          ]
        },
        "id": "fe099778-71f8-46f1-bff7-dae1b30fcc88",
        "outputId": "d1625b9d-df8f-42a6-9271-61c321325c78"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e81b0627ad24768a8010cfeb25b8ec9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/109M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/MLsheenu/AI_COMPANION_finetuned/commit/071fb22c7b1a04a51694e064ac6e02858efe0cc2', commit_message='Upload model', commit_description='', oid='071fb22c7b1a04a51694e064ac6e02858efe0cc2', pr_url=None, repo_url=RepoUrl('https://huggingface.co/MLsheenu/AI_COMPANION_finetuned', endpoint='https://huggingface.co', repo_type='model', repo_id='MLsheenu/AI_COMPANION_finetuned'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fine_tuning.model.push_to_hub(\"AI_COMPANION_finetuned\", private=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bedfbfaa-0d30-49b2-a579-36cf3195fc8c",
      "metadata": {
        "id": "bedfbfaa-0d30-49b2-a579-36cf3195fc8c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}